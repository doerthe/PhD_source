\section{Limits of the approach}\label{sec:limits}
Having introduced the pragmatic proof algorithm and discussed its advantages for hypermedia APIs -- the algorithm is highly adaptive and can cope well with rapidly 
changing environments -- we now want to discuss shortcomings and possible problems of the approach.
Our
goal is to clearly identify for which kinds of use cases we can perform planning by using proofs and for which cases this method is not well suited.

\subsection{Existential rules}
%Not a shortcoming in the classical meaning but a potential source of problems is that the approach uses existential rules.
Our approach relies on existential rules. While initial tests have shown that the EYE reasoner performs well when applying automatically generated RESTdesc 
descriptions~\cite{PP}, it is in general rather easy to construct examples which -- when applying classical inferencing algorithms -- 
lead to infinite loops. To illustrate that, we discuss a classical example problem for existential rules. Consider the following rule:
% \[
% \texttt{:Kurt a :Person.}
% \]
% and the rule
\[
\texttt{ \{?x a :Person\}=>\{?x :mother \_:y. \_:y a :Person.\}. }
\]
This rule means:

\begin{center}\textit{``Every person has a mother and this mother is again a person.''}\end{center}

The moment we have a triple which declares someone as a person, the rule will trigger and add a triple representing
the mother of this person. As this mother again has a mother which then again has a mother and so on, we get into an infinite loop and the reasoning process will not stop.

While the loop we created here can be avoided -- it is rather unusual to write a rule which triggers on its own results -- more complicated loops are more difficult to detect.
%and %to avoid.
A lot of research focusses on how to restrict existential rules in order to guarantee termination %  terminate
%A lot of research focuses on ways to restrict existential rules
(eg \cite{krotzsch2011extending,gottlob2013combining,Baget}). 
These restrictions mostly take combinations of rules into account and cannot be imposed separately on individual rules. % format on every rule individually, 
Therefore such approaches cannot be 
used in the Web with its distributed nature: As we do not know which APIs can and will be combined using our algorithm, we cannot ask the provider of one service 
to write its description in a way that it does not lead to infinite loops when being combined with another service.

Instead of restricting the rules, we work with different reasoning tactics: A reasoning tactic determines when a reasoner stops 
(for example after a certain number of rule-applications  
or directly after one instance of the goal is found), it controls the order in which rules are applied 
(following Prolog's left-most selection rule~\cite{nilsson} or any other similar rule) and it can exclude rule applications based on their consequence (for example 
no applying a rule for whose consequence the dataset already contains a ground instance). Such strategies are implemented in EYE~\cite{eye} and have proven 
to be useful in practice. 
The aim of the pragmatic proof algorithm is not to find all plans or the best plan towards a goal, its aim is to find one possible plan and then execute it.
In this set-up it makes sense to try -- if needed -- different reasoning strategies on a API composition problem till one solution is found.



% 
% One source for problems with the approach 
% While performance 
% tests showed that the reasoning time 
% 
% 
% 
% We start by discussing the performance of the approach. Tests have shown that 
% 
% The pragmatic proof algorithm presented in the previous section is designed for hypermedia APIs 
% 
% 
% has been developed for hypermedia APIs in the Web and in general, it performs very 
% 
% 
% The tests which have been done about this approach as for example performed by Verborgh \cite{verborgh_phd_2014} also showed a very positive result:
% 
% 
% Here I want to explain that it is difficult to express change in RESTdesc and that we cannot generate more than on path. Maybe I also want to mention that the reasoner
% in some cases only stops if we apply specific strategies.
% 
% 
% - Verborgh showed that the approach performs well enough for the Web. But here, we need to be careful:
% 
% Even though the experiments conducted to test the performance of the approach~\cite[ch. 5]{verborgh_phd_2014} showed very pr
% 
% existential rules can be problematic in general: bring the mother example

\subsection{Choices}
In the previous section we already explained, that the pragmatic proof algorithm is not designed to find different paths towards a goal but to find \emph{one} valid path.
In settings where different alternatives need to be provided the approach cannot be applied: 
The purpose of a proof in the classical sense is to provide evidence for a derived fact. 
Once such an evidence is found, 
it does not really make sense to search for an alternative 
evidence. Therefore, \nthree reasoners are not optimised to search alternative proofs. But even if they were,
the fact that we
%If we would search for alternative paths using the approach presented, the fact that the approach combines
combine reasoning on background knowledge and application 
of \restdesc descriptions would quickly lead to performance problems:
From the reasoner's point of view there is no difference between \restdesc descriptions and other rules. Alternative proofs would also need to take all alternative 
ways to derive background knowledge into account.  If we for example have the following knowledge about \texttt{:Kurt}
\[
\texttt{:Kurt a :Researcher; :Man; :Mathematician.}
\]
and we know that every \texttt{:Researcher}, every \texttt{:Man} and also every \texttt{:Mathematician} is a \texttt{:Person}, we need to always generate three different 
proofs whenever the knowledge that \texttt{:Kurt} is a \texttt{:Person} is required. 
These alternatives then need to be combined with all alternatives we have for all other derivations involved in a proof.
The complex problem of calculating different combinations of \restdesc descriptions in order to fulfil a goal gets
even more complex and -- depending on the number of rules involved -- not solvable by a normal computer.



\subsection{Change}
Another shortcoming of the approach of using classical proofs as plans towards a goal is that in this set-up it is not possible to express \emph{change}. It is
always possible to add new data and triples but it is not possible to remove triples. 
We can therefore not (or at least not in an easy way) describe that an API operation changes, for example, the state of the light from off to on. 
We cannot express that  the triple
\[
\texttt{:myLight :status :off.}
\]
gets \emph{replaced} by
\[
\texttt{:myLight :status :on.}
\]
The reason for that is that \nthreelogic -- such as most Web logics -- is based on first order logic where we have the principle of monotonicity: 
If a formula $\phi$ follows from 
another formula $\psi$ this derivation still needs to be true when we add further knowledge to the premise. From $\gamma\wedge\psi$ we still need to be able to conclude 
$\phi$ regardless of the concrete shape of $\gamma$. In order to properly model change which includes the possibility to invalidate data we would 
need a non-monotonic logic.

For our API compositions this means that the approach works well if we have settings where many \texttt{GET}-requests are included -- these result in new knowledge -- 
while it can be problematic to -- for example -- include a \texttt{DELETE}-request.

